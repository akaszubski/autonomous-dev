#!/usr/bin/env python3
"""
Unit tests for tech_debt_detector.py - Tech Debt Detection System (Issue #162).

TDD RED PHASE - These tests WILL FAIL until implementation exists.

Tests cover:
- Severity enum and comparison
- TechDebtIssue dataclass creation and validation
- TechDebtReport aggregation and blocking logic
- Large file detection (1000 LOC warn, 1500 LOC block)
- Circular import detection (AST-based analysis)
- RED test accumulation detection (pytest markers)
- Config class proliferation detection
- Duplicate directory detection (similarity thresholds)
- Dead code detection (unused imports/functions)
- Complexity calculation (McCabe/radon integration)
- Edge cases: empty project, no Python files, permission errors
- Integration with reviewer checklist

Test Strategy:
- Class-based tests with fixtures
- tmp_path for temporary project structures
- AAA pattern (Arrange-Act-Assert)
- Mock file system operations for edge cases
- Follow CodebaseAnalyzer test patterns

Coverage Target: 95%+ for tech_debt_detector.py

Date: 2025-12-25
Issue: #162 (Tech Debt Detection System)
Agent: test-master
Phase: TDD Red (tests written BEFORE implementation)
Status: RED (all tests failing - module doesn't exist yet)
"""

import sys
import pytest
from pathlib import Path
from typing import List, Dict, Any
from unittest.mock import Mock, patch, mock_open
from enum import Enum

# Add lib directory to path for imports
sys.path.insert(
    0,
    str(
        Path(__file__).parent.parent.parent.parent
        / "plugins"
        / "autonomous-dev"
        / "lib"
    ),
)

# Import will fail - module doesn't exist yet (TDD!)
try:
    from tech_debt_detector import (
        Severity,
        TechDebtIssue,
        TechDebtReport,
        TechDebtDetector,
    )
except ImportError as e:
    pytest.skip(f"Implementation not found (TDD red phase): {e}", allow_module_level=True)

# Check if radon is available (optional dependency for complexity tests)
try:
    from radon.complexity import cc_visit
    RADON_AVAILABLE = True
except ImportError:
    RADON_AVAILABLE = False

# Skip marker for tests that require radon
requires_radon = pytest.mark.skipif(not RADON_AVAILABLE, reason="radon not installed")


# =============================================================================
# Test Fixtures
# =============================================================================

@pytest.fixture
def temp_project(tmp_path):
    """Create temporary project directory."""
    project = tmp_path / "test_project"
    project.mkdir()
    return project


@pytest.fixture
def python_file_small(temp_project):
    """Create small Python file (50 LOC)."""
    file_path = temp_project / "small.py"
    content = "\n".join([f"# Line {i}" for i in range(50)])
    file_path.write_text(content)
    return file_path


@pytest.fixture
def python_file_medium(temp_project):
    """Create medium Python file (800 LOC)."""
    file_path = temp_project / "medium.py"
    content = "\n".join([f"# Line {i}" for i in range(800)])
    file_path.write_text(content)
    return file_path


@pytest.fixture
def python_file_large(temp_project):
    """Create large Python file (1200 LOC - warning threshold)."""
    file_path = temp_project / "large.py"
    content = "\n".join([f"# Line {i}" for i in range(1200)])
    file_path.write_text(content)
    return file_path


@pytest.fixture
def python_file_huge(temp_project):
    """Create huge Python file (1600 LOC - blocking threshold)."""
    file_path = temp_project / "huge.py"
    content = "\n".join([f"# Line {i}" for i in range(1600)])
    file_path.write_text(content)
    return file_path


@pytest.fixture
def circular_import_files(temp_project):
    """Create files with circular imports."""
    # module_a.py imports module_b
    (temp_project / "module_a.py").write_text(
        "from module_b import func_b\n\ndef func_a():\n    pass\n"
    )
    # module_b.py imports module_a (circular!)
    (temp_project / "module_b.py").write_text(
        "from module_a import func_a\n\ndef func_b():\n    pass\n"
    )
    return temp_project


@pytest.fixture
def complex_circular_imports(temp_project):
    """Create complex circular import chain (A -> B -> C -> A)."""
    (temp_project / "mod_a.py").write_text(
        "from mod_b import func_b\n\ndef func_a():\n    pass\n"
    )
    (temp_project / "mod_b.py").write_text(
        "from mod_c import func_c\n\ndef func_b():\n    pass\n"
    )
    (temp_project / "mod_c.py").write_text(
        "from mod_a import func_a\n\ndef func_c():\n    pass\n"
    )
    return temp_project


@pytest.fixture
def test_file_with_red_markers(temp_project):
    """Create test file with RED pytest markers."""
    content = """
import pytest

@pytest.mark.RED
def test_not_implemented_1():
    assert False

@pytest.mark.RED
def test_not_implemented_2():
    assert False

@pytest.mark.RED
def test_not_implemented_3():
    assert False

@pytest.mark.RED
def test_not_implemented_4():
    assert False

@pytest.mark.RED
def test_not_implemented_5():
    assert False

@pytest.mark.RED
def test_not_implemented_6():
    assert False  # 6 RED tests = threshold violation
"""
    (temp_project / "test_feature.py").write_text(content)
    return temp_project


@pytest.fixture
def config_proliferation_files(temp_project):
    """Create project with many config classes."""
    config_dir = temp_project / "config"
    config_dir.mkdir()

    # Create 25 config classes (exceeds threshold of 20)
    for i in range(25):
        content = f"""
class Config{i}:
    def __init__(self):
        self.setting = {i}
"""
        (config_dir / f"config_{i}.py").write_text(content)

    return temp_project


@pytest.fixture
def duplicate_directories(temp_project):
    """Create duplicate directory structures (> 80% similarity)."""
    # Create dir1 with files (5 files)
    dir1 = temp_project / "module_v1"
    dir1.mkdir()
    (dir1 / "auth.py").write_text("def authenticate(): pass\n")
    (dir1 / "utils.py").write_text("def helper(): pass\n")
    (dir1 / "models.py").write_text("class User: pass\n")
    (dir1 / "handlers.py").write_text("def handle(): pass\n")
    (dir1 / "services.py").write_text("def serve(): pass\n")

    # Create dir2 with 100% same files (5/5 = 100% similarity = duplicate!)
    dir2 = temp_project / "module_v2"
    dir2.mkdir()
    (dir2 / "auth.py").write_text("def authenticate(): pass\n")  # Same
    (dir2 / "utils.py").write_text("def helper(): pass\n")  # Same
    (dir2 / "models.py").write_text("class User: pass\n")  # Same
    (dir2 / "handlers.py").write_text("def handle(): pass\n")  # Same
    (dir2 / "services.py").write_text("def serve(): pass\n")  # Same

    return temp_project


@pytest.fixture
def dead_code_file(temp_project):
    """Create file with dead code (unused imports/functions)."""
    content = """
import os  # Used
import sys  # Unused
import json  # Unused
from pathlib import Path  # Used

def used_function():
    return Path.cwd()

def unused_function():
    pass

def another_unused_function():
    pass

if __name__ == "__main__":
    used_function()
"""
    (temp_project / "dead_code.py").write_text(content)
    return temp_project


@pytest.fixture
def complex_function_file(temp_project):
    """Create file with complex functions (high McCabe complexity)."""
    content = """
def simple_function():
    return 42

def moderate_complexity():
    # Complexity ~12 (just over threshold of 11)
    result = 0
    for i in range(10):
        if i % 2 == 0:
            if i > 5:
                result += i
            else:
                result -= i
        else:
            if i < 3:
                result *= 2
            else:
                result /= 2
    return result

def high_complexity():
    # Complexity ~25 (HIGH severity)
    result = 0
    for i in range(10):
        for j in range(10):
            if i % 2 == 0:
                if j % 2 == 0:
                    if i > j:
                        result += 1
                    else:
                        result -= 1
                else:
                    if i < j:
                        result *= 2
                    else:
                        result /= 2
            else:
                if j > 5:
                    result += j
                else:
                    result -= j
    return result

def critical_complexity():
    # Complexity ~55 (CRITICAL severity)
    result = 0
    for i in range(10):
        for j in range(10):
            for k in range(5):
                if i % 2 == 0:
                    if j % 2 == 0:
                        if k % 2 == 0:
                            if i > j:
                                if j > k:
                                    result += 1
                                else:
                                    result -= 1
                            else:
                                if k > i:
                                    result *= 2
                                else:
                                    result /= 2
                        else:
                            if i < k:
                                result += k
                            else:
                                result -= k
                    else:
                        if k > 2:
                            result *= j
                        else:
                            result /= j
                else:
                    if j > 5:
                        if k < 3:
                            result += 1
                        else:
                            result -= 1
                    else:
                        result *= 2
    return result
"""
    (temp_project / "complexity.py").write_text(content)
    return temp_project


# =============================================================================
# SECTION 1: Severity Enum Tests (5 tests)
# =============================================================================

class TestSeverityEnum:
    """Test Severity enum values and comparison."""

    def test_severity_values_exist(self):
        """Test that all severity levels are defined."""
        # Arrange & Act & Assert
        assert hasattr(Severity, 'CRITICAL')
        assert hasattr(Severity, 'HIGH')
        assert hasattr(Severity, 'MEDIUM')
        assert hasattr(Severity, 'LOW')

    def test_severity_ordering(self):
        """Test that severities can be compared (CRITICAL > HIGH > MEDIUM > LOW)."""
        # Arrange & Act & Assert
        assert Severity.CRITICAL.value > Severity.HIGH.value
        assert Severity.HIGH.value > Severity.MEDIUM.value
        assert Severity.MEDIUM.value > Severity.LOW.value

    def test_severity_equality(self):
        """Test severity equality comparison."""
        # Arrange & Act & Assert
        assert Severity.CRITICAL == Severity.CRITICAL
        assert Severity.HIGH != Severity.MEDIUM

    def test_severity_string_representation(self):
        """Test severity string representation."""
        # Arrange & Act & Assert
        assert str(Severity.CRITICAL) in ["Severity.CRITICAL", "CRITICAL"]
        assert str(Severity.LOW) in ["Severity.LOW", "LOW"]

    def test_severity_is_enum(self):
        """Test that Severity is an Enum type."""
        # Arrange & Act & Assert
        assert issubclass(Severity, Enum)


# =============================================================================
# SECTION 2: TechDebtIssue Dataclass Tests (8 tests)
# =============================================================================

class TestTechDebtIssue:
    """Test TechDebtIssue dataclass creation and validation."""

    def test_create_tech_debt_issue(self):
        """Test creating a tech debt issue with all fields."""
        # Arrange & Act
        issue = TechDebtIssue(
            category="large_file",
            severity=Severity.HIGH,
            file_path="/path/to/file.py",
            metric_value=1200,
            threshold=1000,
            message="File exceeds size threshold",
            recommendation="Consider splitting into smaller modules"
        )

        # Assert
        assert issue.category == "large_file"
        assert issue.severity == Severity.HIGH
        assert issue.file_path == "/path/to/file.py"
        assert issue.metric_value == 1200
        assert issue.threshold == 1000
        assert issue.message == "File exceeds size threshold"
        assert issue.recommendation == "Consider splitting into smaller modules"

    def test_tech_debt_issue_required_fields(self):
        """Test that required fields are enforced."""
        # Arrange & Act & Assert - Should create successfully with all required fields
        issue = TechDebtIssue(
            category="test_category",
            severity=Severity.MEDIUM,
            file_path="/test/path",
            metric_value=100,
            threshold=50,
            message="Test message",
            recommendation="Test recommendation"
        )
        assert issue is not None

    def test_tech_debt_issue_severity_types(self):
        """Test creating issues with different severity levels."""
        # Arrange & Act
        critical_issue = TechDebtIssue(
            category="circular_import",
            severity=Severity.CRITICAL,
            file_path="/path/module.py",
            metric_value=1,
            threshold=0,
            message="Circular import detected",
            recommendation="Refactor to break cycle"
        )

        low_issue = TechDebtIssue(
            category="dead_code",
            severity=Severity.LOW,
            file_path="/path/utils.py",
            metric_value=2,
            threshold=0,
            message="Unused imports detected",
            recommendation="Remove unused imports"
        )

        # Assert
        assert critical_issue.severity == Severity.CRITICAL
        assert low_issue.severity == Severity.LOW

    def test_tech_debt_issue_equality(self):
        """Test tech debt issue equality comparison."""
        # Arrange
        issue1 = TechDebtIssue(
            category="test",
            severity=Severity.HIGH,
            file_path="/path",
            metric_value=100,
            threshold=50,
            message="Test",
            recommendation="Fix it"
        )

        issue2 = TechDebtIssue(
            category="test",
            severity=Severity.HIGH,
            file_path="/path",
            metric_value=100,
            threshold=50,
            message="Test",
            recommendation="Fix it"
        )

        # Act & Assert
        assert issue1 == issue2

    def test_tech_debt_issue_different_severity(self):
        """Test that issues with different severities are not equal."""
        # Arrange
        issue1 = TechDebtIssue(
            category="test",
            severity=Severity.HIGH,
            file_path="/path",
            metric_value=100,
            threshold=50,
            message="Test",
            recommendation="Fix"
        )

        issue2 = TechDebtIssue(
            category="test",
            severity=Severity.MEDIUM,
            file_path="/path",
            metric_value=100,
            threshold=50,
            message="Test",
            recommendation="Fix"
        )

        # Act & Assert
        assert issue1 != issue2

    def test_tech_debt_issue_string_representation(self):
        """Test tech debt issue string representation."""
        # Arrange
        issue = TechDebtIssue(
            category="complexity",
            severity=Severity.HIGH,
            file_path="/code/complex.py",
            metric_value=25,
            threshold=11,
            message="High complexity detected",
            recommendation="Simplify logic"
        )

        # Act
        issue_str = str(issue)

        # Assert
        assert "complexity" in issue_str.lower()
        assert "HIGH" in issue_str or "high" in issue_str
        assert "/code/complex.py" in issue_str

    def test_tech_debt_issue_metric_comparison(self):
        """Test that metric_value can be compared to threshold."""
        # Arrange
        issue = TechDebtIssue(
            category="test",
            severity=Severity.HIGH,
            file_path="/path",
            metric_value=1500,
            threshold=1000,
            message="Threshold exceeded",
            recommendation="Fix"
        )

        # Act & Assert
        assert issue.metric_value > issue.threshold
        assert issue.metric_value - issue.threshold == 500

    def test_tech_debt_issue_file_path_types(self):
        """Test that file_path accepts both string and Path objects."""
        # Arrange & Act
        issue1 = TechDebtIssue(
            category="test",
            severity=Severity.LOW,
            file_path="/string/path.py",
            metric_value=10,
            threshold=5,
            message="Test",
            recommendation="Fix"
        )

        issue2 = TechDebtIssue(
            category="test",
            severity=Severity.LOW,
            file_path=Path("/path/object.py"),
            metric_value=10,
            threshold=5,
            message="Test",
            recommendation="Fix"
        )

        # Assert
        assert issue1.file_path is not None
        assert issue2.file_path is not None


# =============================================================================
# SECTION 3: TechDebtReport Tests (10 tests)
# =============================================================================

class TestTechDebtReport:
    """Test TechDebtReport aggregation and blocking logic."""

    def test_create_empty_report(self):
        """Test creating an empty tech debt report."""
        # Arrange & Act
        report = TechDebtReport(issues=[], counts={}, blocked=False)

        # Assert
        assert report.issues == []
        assert report.counts == {}
        assert report.blocked is False

    def test_report_with_single_issue(self):
        """Test report with a single issue."""
        # Arrange
        issue = TechDebtIssue(
            category="test",
            severity=Severity.MEDIUM,
            file_path="/path",
            metric_value=100,
            threshold=50,
            message="Test",
            recommendation="Fix"
        )

        # Act
        report = TechDebtReport(
            issues=[issue],
            counts={Severity.MEDIUM: 1},
            blocked=False
        )

        # Assert
        assert len(report.issues) == 1
        assert report.counts[Severity.MEDIUM] == 1
        assert report.blocked is False

    def test_report_with_multiple_issues(self):
        """Test report with multiple issues of different severities."""
        # Arrange
        issues = [
            TechDebtIssue("test1", Severity.CRITICAL, "/p1", 100, 50, "M1", "R1"),
            TechDebtIssue("test2", Severity.HIGH, "/p2", 90, 50, "M2", "R2"),
            TechDebtIssue("test3", Severity.MEDIUM, "/p3", 80, 50, "M3", "R3"),
            TechDebtIssue("test4", Severity.LOW, "/p4", 70, 50, "M4", "R4"),
        ]

        # Act
        report = TechDebtReport(
            issues=issues,
            counts={
                Severity.CRITICAL: 1,
                Severity.HIGH: 1,
                Severity.MEDIUM: 1,
                Severity.LOW: 1,
            },
            blocked=True  # CRITICAL issue blocks commit
        )

        # Assert
        assert len(report.issues) == 4
        assert report.counts[Severity.CRITICAL] == 1
        assert report.counts[Severity.HIGH] == 1
        assert report.counts[Severity.MEDIUM] == 1
        assert report.counts[Severity.LOW] == 1
        assert report.blocked is True

    def test_report_blocking_on_critical_issue(self):
        """Test that CRITICAL issues set blocked=True."""
        # Arrange
        critical_issue = TechDebtIssue(
            category="circular_import",
            severity=Severity.CRITICAL,
            file_path="/module.py",
            metric_value=1,
            threshold=0,
            message="Circular import",
            recommendation="Refactor"
        )

        # Act
        report = TechDebtReport(
            issues=[critical_issue],
            counts={Severity.CRITICAL: 1},
            blocked=True
        )

        # Assert
        assert report.blocked is True

    def test_report_not_blocking_on_high_severity(self):
        """Test that HIGH severity does NOT block (warning only)."""
        # Arrange
        high_issue = TechDebtIssue(
            category="large_file",
            severity=Severity.HIGH,
            file_path="/big.py",
            metric_value=1200,
            threshold=1000,
            message="Large file",
            recommendation="Split"
        )

        # Act
        report = TechDebtReport(
            issues=[high_issue],
            counts={Severity.HIGH: 1},
            blocked=False  # HIGH doesn't block
        )

        # Assert
        assert report.blocked is False

    def test_report_counts_by_severity(self):
        """Test counting issues by severity level."""
        # Arrange
        issues = [
            TechDebtIssue("t1", Severity.HIGH, "/p1", 100, 50, "M1", "R1"),
            TechDebtIssue("t2", Severity.HIGH, "/p2", 100, 50, "M2", "R2"),
            TechDebtIssue("t3", Severity.MEDIUM, "/p3", 80, 50, "M3", "R3"),
            TechDebtIssue("t4", Severity.LOW, "/p4", 70, 50, "M4", "R4"),
            TechDebtIssue("t5", Severity.LOW, "/p5", 70, 50, "M5", "R5"),
            TechDebtIssue("t6", Severity.LOW, "/p6", 70, 50, "M6", "R6"),
        ]

        # Act
        report = TechDebtReport(
            issues=issues,
            counts={
                Severity.HIGH: 2,
                Severity.MEDIUM: 1,
                Severity.LOW: 3,
            },
            blocked=False
        )

        # Assert
        assert report.counts[Severity.HIGH] == 2
        assert report.counts[Severity.MEDIUM] == 1
        assert report.counts[Severity.LOW] == 3

    def test_report_total_issue_count(self):
        """Test getting total issue count from report."""
        # Arrange
        issues = [
            TechDebtIssue("t1", Severity.HIGH, "/p1", 100, 50, "M1", "R1"),
            TechDebtIssue("t2", Severity.MEDIUM, "/p2", 80, 50, "M2", "R2"),
            TechDebtIssue("t3", Severity.LOW, "/p3", 70, 50, "M3", "R3"),
        ]

        # Act
        report = TechDebtReport(
            issues=issues,
            counts={Severity.HIGH: 1, Severity.MEDIUM: 1, Severity.LOW: 1},
            blocked=False
        )

        # Assert
        assert len(report.issues) == 3
        assert sum(report.counts.values()) == 3

    def test_report_string_representation(self):
        """Test report string representation."""
        # Arrange
        issues = [
            TechDebtIssue("test", Severity.CRITICAL, "/path", 100, 50, "Msg", "Rec"),
        ]
        report = TechDebtReport(
            issues=issues,
            counts={Severity.CRITICAL: 1},
            blocked=True
        )

        # Act
        report_str = str(report)

        # Assert
        assert "1" in report_str  # Issue count
        assert "CRITICAL" in report_str or "critical" in report_str

    def test_report_empty_counts(self):
        """Test report with no issues has zero counts."""
        # Arrange & Act
        report = TechDebtReport(issues=[], counts={}, blocked=False)

        # Assert
        assert sum(report.counts.values()) == 0
        assert report.blocked is False

    def test_report_filter_by_severity(self):
        """Test filtering report issues by severity."""
        # Arrange
        issues = [
            TechDebtIssue("t1", Severity.CRITICAL, "/p1", 100, 50, "M1", "R1"),
            TechDebtIssue("t2", Severity.HIGH, "/p2", 90, 50, "M2", "R2"),
            TechDebtIssue("t3", Severity.MEDIUM, "/p3", 80, 50, "M3", "R3"),
        ]

        report = TechDebtReport(
            issues=issues,
            counts={Severity.CRITICAL: 1, Severity.HIGH: 1, Severity.MEDIUM: 1},
            blocked=True
        )

        # Act
        critical_issues = [i for i in report.issues if i.severity == Severity.CRITICAL]
        high_issues = [i for i in report.issues if i.severity == Severity.HIGH]

        # Assert
        assert len(critical_issues) == 1
        assert len(high_issues) == 1


# =============================================================================
# SECTION 4: Large File Detection Tests (8 tests)
# =============================================================================

class TestDetectLargeFiles:
    """Test detect_large_files() method with various LOC counts."""

    def test_detect_small_file_no_issue(self, temp_project, python_file_small):
        """Test that small files (< 1000 LOC) pass without issues."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert
        assert len(issues) == 0

    def test_detect_medium_file_no_issue(self, temp_project, python_file_medium):
        """Test that medium files (< 1000 LOC) pass without issues."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert
        assert len(issues) == 0

    def test_detect_large_file_warning(self, temp_project, python_file_large):
        """Test that large files (1000-1500 LOC) trigger HIGH severity warning."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert
        assert len(issues) == 1
        assert issues[0].severity == Severity.HIGH
        assert issues[0].category == "large_file"
        assert issues[0].metric_value >= 1000
        assert issues[0].metric_value < 1500
        assert "large.py" in str(issues[0].file_path)

    def test_detect_huge_file_blocking(self, temp_project, python_file_huge):
        """Test that huge files (>= 1500 LOC) trigger CRITICAL severity (blocks commit)."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert
        assert len(issues) == 1
        assert issues[0].severity == Severity.CRITICAL
        assert issues[0].category == "large_file"
        assert issues[0].metric_value >= 1500
        assert "huge.py" in str(issues[0].file_path)

    def test_detect_multiple_large_files(self, temp_project):
        """Test detecting multiple large files."""
        # Arrange
        (temp_project / "large1.py").write_text("\n".join([f"# Line {i}" for i in range(1200)]))
        (temp_project / "large2.py").write_text("\n".join([f"# Line {i}" for i in range(1300)]))
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert
        assert len(issues) == 2
        assert all(i.severity == Severity.HIGH for i in issues)

    def test_detect_exact_threshold_boundaries(self, temp_project):
        """Test exact threshold boundaries (1000 and 1500 LOC)."""
        # Arrange
        # Exactly 1000 LOC (boundary - should warn)
        (temp_project / "boundary1.py").write_text("\n".join([f"# Line {i}" for i in range(1000)]))
        # Exactly 1500 LOC (boundary - should block)
        (temp_project / "boundary2.py").write_text("\n".join([f"# Line {i}" for i in range(1500)]))
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert
        assert len(issues) == 2
        high_issues = [i for i in issues if i.severity == Severity.HIGH]
        critical_issues = [i for i in issues if i.severity == Severity.CRITICAL]
        assert len(high_issues) == 1  # 1000 LOC
        assert len(critical_issues) == 1  # 1500 LOC

    def test_detect_large_files_excludes_tests(self, temp_project):
        """Test that test files are excluded from large file detection."""
        # Arrange
        (temp_project / "test_large.py").write_text("\n".join([f"# Line {i}" for i in range(1200)]))
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert - Test files should be excluded
        assert len(issues) == 0

    def test_detect_large_files_recommendation(self, temp_project, python_file_large):
        """Test that large file issues include helpful recommendations."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_large_files()

        # Assert
        assert len(issues) == 1
        assert "split" in issues[0].recommendation.lower() or "refactor" in issues[0].recommendation.lower()


# =============================================================================
# SECTION 5: Circular Import Detection Tests (8 tests)
# =============================================================================

class TestDetectCircularImports:
    """Test detect_circular_imports() method with AST-based analysis."""

    def test_detect_no_circular_imports(self, temp_project):
        """Test project with no circular imports."""
        # Arrange
        (temp_project / "module_a.py").write_text("def func_a(): pass\n")
        (temp_project / "module_b.py").write_text("from module_a import func_a\n\ndef func_b(): pass\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert
        assert len(issues) == 0

    def test_detect_simple_circular_import(self, temp_project, circular_import_files):
        """Test detecting simple circular import (A -> B -> A)."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert
        assert len(issues) >= 1  # At least one cycle detected
        assert any(i.severity == Severity.CRITICAL for i in issues)
        assert any(i.category == "circular_import" for i in issues)

    def test_detect_complex_circular_import(self, temp_project, complex_circular_imports):
        """Test detecting complex circular import chain (A -> B -> C -> A)."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert
        assert len(issues) >= 1
        assert any(i.severity == Severity.CRITICAL for i in issues)

    def test_circular_import_blocks_commit(self, temp_project, circular_import_files):
        """Test that circular imports have CRITICAL severity (blocks commit)."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert
        assert all(i.severity == Severity.CRITICAL for i in issues)

    def test_circular_import_message_includes_cycle(self, temp_project, circular_import_files):
        """Test that circular import message includes the import cycle."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert
        assert len(issues) >= 1
        # Message should mention the modules in the cycle
        assert any("module_a" in i.message.lower() or "module_b" in i.message.lower() for i in issues)

    def test_circular_import_with_relative_imports(self, temp_project):
        """Test detecting circular imports with relative imports."""
        # Arrange
        pkg_dir = temp_project / "package"
        pkg_dir.mkdir()
        (pkg_dir / "__init__.py").write_text("")
        (pkg_dir / "mod_a.py").write_text("from .mod_b import func_b\n\ndef func_a(): pass\n")
        (pkg_dir / "mod_b.py").write_text("from .mod_a import func_a\n\ndef func_b(): pass\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert
        assert len(issues) >= 1
        assert any(i.severity == Severity.CRITICAL for i in issues)

    def test_circular_import_recommendation(self, temp_project, circular_import_files):
        """Test that circular import issues include helpful recommendations."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert
        assert len(issues) >= 1
        assert any(
            "refactor" in i.recommendation.lower() or "break" in i.recommendation.lower()
            for i in issues
        )

    def test_circular_import_ast_parsing_error(self, temp_project):
        """Test graceful handling of AST parsing errors."""
        # Arrange
        (temp_project / "invalid.py").write_text("def broken syntax here\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_circular_imports()

        # Assert - Should not crash, may return empty or skip invalid file
        assert isinstance(issues, list)


# =============================================================================
# SECTION 6: RED Test Accumulation Detection Tests (7 tests)
# =============================================================================

class TestDetectRedTestAccumulation:
    """Test detect_red_test_accumulation() method with pytest markers."""

    def test_detect_no_red_tests(self, temp_project):
        """Test project with no RED pytest markers."""
        # Arrange
        content = """
import pytest

def test_passing_1():
    assert True

def test_passing_2():
    assert True
"""
        (temp_project / "test_feature.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_red_test_accumulation()

        # Assert
        assert len(issues) == 0

    def test_detect_few_red_tests_ok(self, temp_project):
        """Test that <= 5 RED tests is acceptable."""
        # Arrange
        content = """
import pytest

@pytest.mark.RED
def test_not_impl_1():
    assert False

@pytest.mark.RED
def test_not_impl_2():
    assert False

@pytest.mark.RED
def test_not_impl_3():
    assert False

@pytest.mark.RED
def test_not_impl_4():
    assert False

@pytest.mark.RED
def test_not_impl_5():
    assert False
"""
        (temp_project / "test_feature.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_red_test_accumulation()

        # Assert
        assert len(issues) == 0  # 5 is at threshold, not over

    def test_detect_excessive_red_tests(self, temp_project, test_file_with_red_markers):
        """Test that > 5 RED tests triggers HIGH severity warning."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_red_test_accumulation()

        # Assert
        assert len(issues) == 1
        assert issues[0].severity == Severity.HIGH
        assert issues[0].category == "red_test_accumulation"
        assert issues[0].metric_value > 5

    def test_red_test_accumulation_message(self, temp_project, test_file_with_red_markers):
        """Test that RED test accumulation message includes count."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_red_test_accumulation()

        # Assert
        assert len(issues) == 1
        assert str(issues[0].metric_value) in issues[0].message or "6" in issues[0].message

    def test_red_test_accumulation_recommendation(self, temp_project, test_file_with_red_markers):
        """Test that RED test accumulation includes helpful recommendation."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_red_test_accumulation()

        # Assert
        assert len(issues) == 1
        assert (
            "implement" in issues[0].recommendation.lower() or
            "remove" in issues[0].recommendation.lower()
        )

    def test_red_test_multiple_files(self, temp_project):
        """Test detecting RED tests across multiple test files."""
        # Arrange
        # File 1: 4 RED tests
        content1 = "\n".join([
            "import pytest",
            "@pytest.mark.RED\ndef test_1(): assert False",
            "@pytest.mark.RED\ndef test_2(): assert False",
            "@pytest.mark.RED\ndef test_3(): assert False",
            "@pytest.mark.RED\ndef test_4(): assert False",
        ])
        (temp_project / "test_module1.py").write_text(content1)

        # File 2: 3 RED tests (total 7 > threshold)
        content2 = "\n".join([
            "import pytest",
            "@pytest.mark.RED\ndef test_5(): assert False",
            "@pytest.mark.RED\ndef test_6(): assert False",
            "@pytest.mark.RED\ndef test_7(): assert False",
        ])
        (temp_project / "test_module2.py").write_text(content2)

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_red_test_accumulation()

        # Assert
        # Should detect accumulation (7 total RED tests > 5 threshold)
        assert len(issues) >= 1
        assert any(i.severity == Severity.HIGH for i in issues)

    def test_red_test_case_sensitivity(self, temp_project):
        """Test that RED marker detection is case-sensitive."""
        # Arrange
        content = """
import pytest

@pytest.mark.red  # lowercase - should not count
def test_1():
    assert False

@pytest.mark.RED  # uppercase - should count
def test_2():
    assert False
"""
        (temp_project / "test_feature.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_red_test_accumulation()

        # Assert - Only 1 RED test (uppercase), should not trigger
        assert len(issues) == 0


# =============================================================================
# SECTION 7: Config Proliferation Detection Tests (6 tests)
# =============================================================================

class TestDetectConfigProliferation:
    """Test detect_config_proliferation() method."""

    def test_detect_no_config_proliferation(self, temp_project):
        """Test project with few config classes (< 20)."""
        # Arrange
        for i in range(10):
            (temp_project / f"config_{i}.py").write_text(f"class Config{i}: pass\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_config_proliferation()

        # Assert
        assert len(issues) == 0

    def test_detect_config_proliferation(self, temp_project, config_proliferation_files):
        """Test detecting > 20 config classes triggers MEDIUM severity."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_config_proliferation()

        # Assert
        assert len(issues) == 1
        assert issues[0].severity == Severity.MEDIUM
        assert issues[0].category == "config_proliferation"
        assert issues[0].metric_value > 20

    def test_config_proliferation_counts_classes(self, temp_project):
        """Test that config proliferation counts class definitions."""
        # Arrange
        # Create file with multiple config classes
        content = "\n".join([f"class Config{i}:\n    pass\n" for i in range(25)])
        (temp_project / "all_configs.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_config_proliferation()

        # Assert
        assert len(issues) == 1
        assert issues[0].metric_value >= 25

    def test_config_proliferation_message(self, temp_project, config_proliferation_files):
        """Test that config proliferation message includes count."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_config_proliferation()

        # Assert
        assert len(issues) == 1
        assert "config" in issues[0].message.lower()

    def test_config_proliferation_recommendation(self, temp_project, config_proliferation_files):
        """Test that config proliferation includes helpful recommendation."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_config_proliferation()

        # Assert
        assert len(issues) == 1
        assert (
            "consolidate" in issues[0].recommendation.lower() or
            "centralize" in issues[0].recommendation.lower()
        )

    def test_config_proliferation_excludes_non_config(self, temp_project):
        """Test that only Config* classes are counted."""
        # Arrange
        # Create non-config classes (should not count)
        content = """
class User:
    pass

class Product:
    pass

class Service:
    pass
"""
        for i in range(25):
            (temp_project / f"module_{i}.py").write_text(content)

        # Only 5 actual config classes
        for i in range(5):
            (temp_project / f"config_{i}.py").write_text(f"class Config{i}: pass\n")

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_config_proliferation()

        # Assert
        assert len(issues) == 0  # Only 5 Config* classes, below threshold


# =============================================================================
# SECTION 8: Duplicate Directory Detection Tests (7 tests)
# =============================================================================

class TestDetectDuplicateDirectories:
    """Test detect_duplicate_directories() method with similarity thresholds."""

    def test_detect_no_duplicate_directories(self, temp_project):
        """Test project with unique directories."""
        # Arrange
        dir1 = temp_project / "auth"
        dir1.mkdir()
        (dir1 / "login.py").write_text("def login(): pass\n")

        dir2 = temp_project / "billing"
        dir2.mkdir()
        (dir2 / "invoice.py").write_text("def create_invoice(): pass\n")

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_duplicate_directories()

        # Assert
        assert len(issues) == 0

    def test_detect_duplicate_directories(self, temp_project, duplicate_directories):
        """Test detecting directories with > 80% similarity."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_duplicate_directories()

        # Assert
        assert len(issues) >= 1
        assert any(i.severity == Severity.MEDIUM for i in issues)
        assert any(i.category == "duplicate_directory" for i in issues)

    def test_duplicate_directory_similarity_threshold(self, temp_project):
        """Test that > 80% similarity is detected (using Jaccard index)."""
        # Arrange
        # dir1: 5 files (file_0 through file_4)
        dir1 = temp_project / "version1"
        dir1.mkdir()
        for i in range(5):
            (dir1 / f"file_{i}.py").write_text(f"# Content {i}\n")

        # dir2: All 5 same files + 1 extra (Jaccard = 5/6 = 83.3% > 80%)
        dir2 = temp_project / "version2"
        dir2.mkdir()
        for i in range(5):  # All 5 same files
            (dir2 / f"file_{i}.py").write_text(f"# Content {i}\n")
        (dir2 / "extra.py").write_text("# Extra file\n")  # 1 extra

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_duplicate_directories()

        # Assert
        assert len(issues) >= 1

    def test_duplicate_directory_below_threshold(self, temp_project):
        """Test that < 80% similarity does not trigger detection."""
        # Arrange
        # dir1: 10 files
        dir1 = temp_project / "module_a"
        dir1.mkdir()
        for i in range(10):
            (dir1 / f"file_{i}.py").write_text(f"# Content {i}\n")

        # dir2: 7 same files + 3 different (70% similarity - below threshold)
        dir2 = temp_project / "module_b"
        dir2.mkdir()
        for i in range(7):
            (dir2 / f"file_{i}.py").write_text(f"# Content {i}\n")
        for i in range(3):
            (dir2 / f"different_{i}.py").write_text(f"# Unique {i}\n")

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_duplicate_directories()

        # Assert
        # 70% similarity should not trigger (threshold is > 80%)
        # This assertion might be tricky - adjust based on implementation
        duplicate_issues = [i for i in issues if "module_a" in str(i.file_path) or "module_b" in str(i.file_path)]
        assert len(duplicate_issues) == 0

    def test_duplicate_directory_message(self, temp_project, duplicate_directories):
        """Test that duplicate directory message includes directory names."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_duplicate_directories()

        # Assert
        assert len(issues) >= 1
        # Message should mention the duplicate directories
        assert any(
            "module_v1" in i.message.lower() or "module_v2" in i.message.lower()
            for i in issues
        )

    def test_duplicate_directory_recommendation(self, temp_project, duplicate_directories):
        """Test that duplicate directory includes helpful recommendation."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_duplicate_directories()

        # Assert
        assert len(issues) >= 1
        assert any(
            "consolidate" in i.recommendation.lower() or "merge" in i.recommendation.lower()
            for i in issues
        )

    def test_duplicate_directory_metric_value(self, temp_project, duplicate_directories):
        """Test that metric_value contains similarity percentage."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_duplicate_directories()

        # Assert
        assert len(issues) >= 1
        # Similarity should be > 80 (percentage)
        assert any(i.metric_value > 80 for i in issues)


# =============================================================================
# SECTION 9: Dead Code Detection Tests (7 tests)
# =============================================================================

class TestDetectDeadCode:
    """Test detect_dead_code() method for unused imports/functions."""

    def test_detect_no_dead_code(self, temp_project):
        """Test file with all imports and functions used."""
        # Arrange
        content = """
import os
from pathlib import Path

def use_os():
    return os.getcwd()

def use_path():
    return Path.cwd()

if __name__ == "__main__":
    use_os()
    use_path()
"""
        (temp_project / "clean.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_dead_code()

        # Assert
        assert len(issues) == 0

    def test_detect_unused_imports(self, temp_project):
        """Test detecting unused imports."""
        # Arrange
        content = """
import os  # Used
import sys  # Unused
import json  # Unused

def main():
    return os.getcwd()
"""
        (temp_project / "unused_imports.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_dead_code()

        # Assert
        assert len(issues) >= 1
        assert any(i.severity == Severity.LOW for i in issues)
        assert any(i.category == "dead_code" for i in issues)

    def test_detect_unused_functions(self, temp_project):
        """Test detecting unused functions."""
        # Arrange
        content = """
def used_function():
    return 42

def unused_function():
    pass

def another_unused():
    pass

if __name__ == "__main__":
    used_function()
"""
        (temp_project / "unused_funcs.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_dead_code()

        # Assert
        assert len(issues) >= 1
        assert any(i.severity == Severity.LOW for i in issues)

    def test_dead_code_severity_is_low(self, temp_project, dead_code_file):
        """Test that dead code issues have LOW severity (doesn't block)."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_dead_code()

        # Assert
        assert len(issues) >= 1
        assert all(i.severity == Severity.LOW for i in issues)

    def test_dead_code_message(self, temp_project, dead_code_file):
        """Test that dead code message includes details."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_dead_code()

        # Assert
        assert len(issues) >= 1
        # Message should mention unused imports or functions
        assert any(
            "unused" in i.message.lower() or "dead" in i.message.lower()
            for i in issues
        )

    def test_dead_code_recommendation(self, temp_project, dead_code_file):
        """Test that dead code includes helpful recommendation."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_dead_code()

        # Assert
        assert len(issues) >= 1
        assert any("remove" in i.recommendation.lower() for i in issues)

    def test_dead_code_excludes_tests(self, temp_project):
        """Test that test files are excluded from dead code detection."""
        # Arrange
        content = """
import pytest  # Used only in test decorator
import json  # Unused but in test file

def test_something():
    assert True
"""
        (temp_project / "test_feature.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.detect_dead_code()

        # Assert
        # Test files should be excluded or have different rules
        test_issues = [i for i in issues if "test_feature" in str(i.file_path)]
        assert len(test_issues) == 0


# =============================================================================
# SECTION 10: Complexity Calculation Tests (10 tests)
# =============================================================================

class TestCalculateComplexity:
    """Test calculate_complexity() method with McCabe/radon integration."""

    def test_calculate_simple_function_complexity(self, temp_project):
        """Test calculating complexity for simple function (< 11)."""
        # Arrange
        content = """
def simple():
    return 42
"""
        (temp_project / "simple.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        assert len(issues) == 0  # Low complexity, no issue

    def test_calculate_moderate_complexity(self, temp_project):
        """Test calculating moderate complexity (11-20) triggers MEDIUM severity."""
        # Arrange
        content = """
def moderate():
    result = 0
    for i in range(10):
        if i % 2 == 0:
            if i > 5:
                result += i
            else:
                result -= i
        else:
            if i < 3:
                result *= 2
            else:
                result /= 2
    return result
"""
        (temp_project / "moderate.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        # Complexity should be ~12 (MEDIUM severity)
        moderate_issues = [i for i in issues if i.severity == Severity.MEDIUM]
        assert len(moderate_issues) >= 0  # May or may not detect depending on radon

    @requires_radon
    def test_calculate_high_complexity(self, temp_project, complex_function_file):
        """Test calculating high complexity (20-50) triggers HIGH severity."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        # Should detect high_complexity function
        high_issues = [i for i in issues if i.severity == Severity.HIGH]
        assert len(high_issues) >= 1

    @requires_radon
    def test_calculate_critical_complexity(self, temp_project, complex_function_file):
        """Test calculating critical complexity (> 50) triggers CRITICAL severity."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        # Should detect critical_complexity function
        critical_issues = [i for i in issues if i.severity == Severity.CRITICAL]
        assert len(critical_issues) >= 1

    @requires_radon
    def test_complexity_thresholds(self, temp_project, complex_function_file):
        """Test that complexity thresholds are correctly applied."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        # Should have issues at different severity levels
        medium_issues = [i for i in issues if i.severity == Severity.MEDIUM]
        high_issues = [i for i in issues if i.severity == Severity.HIGH]
        critical_issues = [i for i in issues if i.severity == Severity.CRITICAL]

        # Depending on radon's exact calculation, we should have some issues
        assert len(medium_issues) + len(high_issues) + len(critical_issues) > 0

    @requires_radon
    def test_complexity_metric_value(self, temp_project, complex_function_file):
        """Test that metric_value contains McCabe complexity score."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        assert len(issues) >= 1
        # All complexity issues should have metric_value > 11
        assert all(i.metric_value > 11 for i in issues if i.category == "complexity")

    @requires_radon
    def test_complexity_message_includes_function_name(self, temp_project, complex_function_file):
        """Test that complexity message includes function name."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        assert len(issues) >= 1
        # Message should mention a function name
        assert any(
            "function" in i.message.lower() or "complexity" in i.message.lower()
            for i in issues
        )

    @requires_radon
    def test_complexity_recommendation(self, temp_project, complex_function_file):
        """Test that complexity issues include helpful recommendations."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        assert len(issues) >= 1
        assert any(
            "simplify" in i.recommendation.lower() or "refactor" in i.recommendation.lower()
            for i in issues
        )

    def test_complexity_excludes_simple_functions(self, temp_project):
        """Test that simple functions (< 11) are not flagged."""
        # Arrange
        content = """
def func1():
    return 1

def func2():
    return 2

def func3(x):
    if x > 0:
        return x
    return 0
"""
        (temp_project / "simple_funcs.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        assert len(issues) == 0  # No complexity issues

    def test_complexity_radon_integration(self, temp_project):
        """Test that radon library is used for complexity calculation."""
        # Arrange
        content = """
def complex_func():
    for i in range(10):
        for j in range(10):
            if i > j:
                if i % 2 == 0:
                    print(i)
                else:
                    print(j)
"""
        (temp_project / "radon_test.py").write_text(content)
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        issues = detector.calculate_complexity()

        # Assert
        # This test verifies radon integration by checking for complexity detection
        # Exact result depends on radon's calculation
        assert isinstance(issues, list)


# =============================================================================
# SECTION 11: TechDebtDetector.analyze() Orchestration Tests (8 tests)
# =============================================================================

class TestAnalyzeOrchestration:
    """Test TechDebtDetector.analyze() method orchestration."""

    def test_analyze_clean_project(self, temp_project):
        """Test analyzing clean project with no issues."""
        # Arrange
        (temp_project / "clean.py").write_text("def hello(): return 'world'\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)
        assert len(report.issues) == 0
        assert report.blocked is False

    def test_analyze_calls_all_detectors(self, temp_project):
        """Test that analyze() calls all detection methods."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Mock all detection methods
        with patch.object(detector, 'detect_large_files', return_value=[]):
            with patch.object(detector, 'detect_circular_imports', return_value=[]):
                with patch.object(detector, 'detect_red_test_accumulation', return_value=[]):
                    with patch.object(detector, 'detect_config_proliferation', return_value=[]):
                        with patch.object(detector, 'detect_duplicate_directories', return_value=[]):
                            with patch.object(detector, 'detect_dead_code', return_value=[]):
                                with patch.object(detector, 'calculate_complexity', return_value=[]):
                                    # Act
                                    report = detector.analyze()

                                    # Assert
                                    detector.detect_large_files.assert_called_once()
                                    detector.detect_circular_imports.assert_called_once()
                                    detector.detect_red_test_accumulation.assert_called_once()
                                    detector.detect_config_proliferation.assert_called_once()
                                    detector.detect_duplicate_directories.assert_called_once()
                                    detector.detect_dead_code.assert_called_once()
                                    detector.calculate_complexity.assert_called_once()

    def test_analyze_aggregates_issues(self, temp_project):
        """Test that analyze() aggregates issues from all detectors."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Mock detectors to return issues
        issue1 = TechDebtIssue("test1", Severity.HIGH, "/p1", 100, 50, "M1", "R1")
        issue2 = TechDebtIssue("test2", Severity.MEDIUM, "/p2", 80, 50, "M2", "R2")
        issue3 = TechDebtIssue("test3", Severity.LOW, "/p3", 60, 50, "M3", "R3")

        with patch.object(detector, 'detect_large_files', return_value=[issue1]):
            with patch.object(detector, 'detect_circular_imports', return_value=[]):
                with patch.object(detector, 'detect_red_test_accumulation', return_value=[issue2]):
                    with patch.object(detector, 'detect_config_proliferation', return_value=[]):
                        with patch.object(detector, 'detect_duplicate_directories', return_value=[]):
                            with patch.object(detector, 'detect_dead_code', return_value=[issue3]):
                                with patch.object(detector, 'calculate_complexity', return_value=[]):
                                    # Act
                                    report = detector.analyze()

                                    # Assert
                                    assert len(report.issues) == 3
                                    assert issue1 in report.issues
                                    assert issue2 in report.issues
                                    assert issue3 in report.issues

    def test_analyze_counts_by_severity(self, temp_project):
        """Test that analyze() correctly counts issues by severity."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        issues = [
            TechDebtIssue("t1", Severity.CRITICAL, "/p1", 100, 50, "M1", "R1"),
            TechDebtIssue("t2", Severity.CRITICAL, "/p2", 100, 50, "M2", "R2"),
            TechDebtIssue("t3", Severity.HIGH, "/p3", 90, 50, "M3", "R3"),
            TechDebtIssue("t4", Severity.MEDIUM, "/p4", 80, 50, "M4", "R4"),
            TechDebtIssue("t5", Severity.LOW, "/p5", 70, 50, "M5", "R5"),
        ]

        with patch.object(detector, 'detect_large_files', return_value=issues[:2]):
            with patch.object(detector, 'detect_circular_imports', return_value=[]):
                with patch.object(detector, 'detect_red_test_accumulation', return_value=[issues[2]]):
                    with patch.object(detector, 'detect_config_proliferation', return_value=[issues[3]]):
                        with patch.object(detector, 'detect_duplicate_directories', return_value=[]):
                            with patch.object(detector, 'detect_dead_code', return_value=[issues[4]]):
                                with patch.object(detector, 'calculate_complexity', return_value=[]):
                                    # Act
                                    report = detector.analyze()

                                    # Assert
                                    assert report.counts[Severity.CRITICAL] == 2
                                    assert report.counts[Severity.HIGH] == 1
                                    assert report.counts[Severity.MEDIUM] == 1
                                    assert report.counts[Severity.LOW] == 1

    def test_analyze_blocks_on_critical(self, temp_project):
        """Test that analyze() sets blocked=True when CRITICAL issues found."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        critical_issue = TechDebtIssue("circ", Severity.CRITICAL, "/p", 1, 0, "Critical", "Fix")

        with patch.object(detector, 'detect_large_files', return_value=[]):
            with patch.object(detector, 'detect_circular_imports', return_value=[critical_issue]):
                with patch.object(detector, 'detect_red_test_accumulation', return_value=[]):
                    with patch.object(detector, 'detect_config_proliferation', return_value=[]):
                        with patch.object(detector, 'detect_duplicate_directories', return_value=[]):
                            with patch.object(detector, 'detect_dead_code', return_value=[]):
                                with patch.object(detector, 'calculate_complexity', return_value=[]):
                                    # Act
                                    report = detector.analyze()

                                    # Assert
                                    assert report.blocked is True

    def test_analyze_does_not_block_on_high(self, temp_project):
        """Test that analyze() does NOT block on HIGH severity issues."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        high_issue = TechDebtIssue("large", Severity.HIGH, "/p", 1200, 1000, "Large", "Split")

        with patch.object(detector, 'detect_large_files', return_value=[high_issue]):
            with patch.object(detector, 'detect_circular_imports', return_value=[]):
                with patch.object(detector, 'detect_red_test_accumulation', return_value=[]):
                    with patch.object(detector, 'detect_config_proliferation', return_value=[]):
                        with patch.object(detector, 'detect_duplicate_directories', return_value=[]):
                            with patch.object(detector, 'detect_dead_code', return_value=[]):
                                with patch.object(detector, 'calculate_complexity', return_value=[]):
                                    # Act
                                    report = detector.analyze()

                                    # Assert
                                    assert report.blocked is False

    def test_analyze_returns_tech_debt_report(self, temp_project):
        """Test that analyze() returns TechDebtReport instance."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)

    def test_analyze_with_mixed_severities(self, temp_project):
        """Test analyze() with issues of all severity levels."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        issues = [
            TechDebtIssue("t1", Severity.CRITICAL, "/p1", 100, 50, "M1", "R1"),
            TechDebtIssue("t2", Severity.HIGH, "/p2", 90, 50, "M2", "R2"),
            TechDebtIssue("t3", Severity.MEDIUM, "/p3", 80, 50, "M3", "R3"),
            TechDebtIssue("t4", Severity.LOW, "/p4", 70, 50, "M4", "R4"),
        ]

        with patch.object(detector, 'detect_large_files', return_value=[issues[0]]):
            with patch.object(detector, 'detect_circular_imports', return_value=[]):
                with patch.object(detector, 'detect_red_test_accumulation', return_value=[issues[1]]):
                    with patch.object(detector, 'detect_config_proliferation', return_value=[issues[2]]):
                        with patch.object(detector, 'detect_duplicate_directories', return_value=[]):
                            with patch.object(detector, 'detect_dead_code', return_value=[issues[3]]):
                                with patch.object(detector, 'calculate_complexity', return_value=[]):
                                    # Act
                                    report = detector.analyze()

                                    # Assert
                                    assert len(report.issues) == 4
                                    assert report.blocked is True  # CRITICAL present


# =============================================================================
# SECTION 12: Edge Cases Tests (10 tests)
# =============================================================================

class TestEdgeCases:
    """Test edge cases: empty project, no Python files, permission errors."""

    def test_empty_project_directory(self, temp_project):
        """Test analyzing completely empty project directory."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)
        assert len(report.issues) == 0
        assert report.blocked is False

    def test_project_with_no_python_files(self, temp_project):
        """Test project with no .py files."""
        # Arrange
        (temp_project / "README.md").write_text("# Project\n")
        (temp_project / "config.json").write_text("{}\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)
        assert len(report.issues) == 0

    def test_project_with_subdirectories(self, temp_project):
        """Test project with nested directory structure."""
        # Arrange
        src_dir = temp_project / "src"
        src_dir.mkdir()
        (src_dir / "module.py").write_text("def func(): pass\n")

        tests_dir = temp_project / "tests"
        tests_dir.mkdir()
        (tests_dir / "test_module.py").write_text("def test_func(): pass\n")

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)

    def test_permission_error_handling(self, temp_project):
        """Test graceful handling of permission errors."""
        # Arrange
        detector = TechDebtDetector(project_root=temp_project)

        # Mock file operation to raise PermissionError
        with patch('pathlib.Path.read_text', side_effect=PermissionError("Access denied")):
            # Act
            report = detector.analyze()

            # Assert - Should not crash
            assert isinstance(report, TechDebtReport)

    def test_invalid_python_syntax(self, temp_project):
        """Test handling of files with invalid Python syntax."""
        # Arrange
        (temp_project / "invalid.py").write_text("def broken syntax here\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert - Should not crash
        assert isinstance(report, TechDebtReport)

    def test_binary_files_excluded(self, temp_project):
        """Test that binary files are excluded from analysis."""
        # Arrange
        (temp_project / "image.png").write_bytes(b'\x89PNG\r\n\x1a\n')
        (temp_project / "data.bin").write_bytes(b'\x00\x01\x02\x03')
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)

    def test_symlink_handling(self, temp_project):
        """Test handling of symbolic links."""
        # Arrange
        (temp_project / "real_file.py").write_text("def func(): pass\n")
        link_path = temp_project / "link.py"

        try:
            link_path.symlink_to(temp_project / "real_file.py")
        except OSError:
            pytest.skip("Symlinks not supported on this platform")

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)

    def test_very_deep_nesting(self, temp_project):
        """Test handling of very deep directory nesting."""
        # Arrange
        deep_path = temp_project
        for i in range(20):
            deep_path = deep_path / f"level_{i}"
            deep_path.mkdir()

        (deep_path / "module.py").write_text("def func(): pass\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)

    def test_special_characters_in_filenames(self, temp_project):
        """Test handling of files with special characters in names."""
        # Arrange
        (temp_project / "file with spaces.py").write_text("def func(): pass\n")
        (temp_project / "file-with-dashes.py").write_text("def func2(): pass\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)

    def test_unicode_in_file_content(self, temp_project):
        """Test handling of Unicode characters in file content."""
        # Arrange
        content = """
# -*- coding: utf-8 -*-
def hello():
    return " "
"""
        (temp_project / "unicode.py").write_text(content, encoding='utf-8')
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert isinstance(report, TechDebtReport)


# =============================================================================
# SECTION 13: Integration Tests (5 tests)
# =============================================================================

class TestIntegration:
    """Integration tests for complete tech debt detection workflow."""

    def test_end_to_end_clean_project(self, temp_project):
        """Test complete workflow on clean project."""
        # Arrange
        (temp_project / "main.py").write_text("""
def greet(name):
    return f"Hello, {name}!"

if __name__ == "__main__":
    print(greet("World"))
""")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert len(report.issues) == 0
        assert report.blocked is False

    def test_end_to_end_problematic_project(self, temp_project):
        """Test complete workflow on project with multiple issues."""
        # Arrange
        # Large file (1200 LOC - HIGH)
        (temp_project / "large.py").write_text("\n".join([f"# Line {i}" for i in range(1200)]))

        # Circular imports (CRITICAL)
        (temp_project / "mod_a.py").write_text("from mod_b import func_b\n\ndef func_a(): pass\n")
        (temp_project / "mod_b.py").write_text("from mod_a import func_a\n\ndef func_b(): pass\n")

        # Dead code (LOW) - Need 2+ unused imports to trigger detection
        (temp_project / "dead.py").write_text("""
import sys  # Unused
import json  # Unused
import os

def main():
    return os.getcwd()
""")

        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report = detector.analyze()

        # Assert
        assert len(report.issues) >= 3  # At least 3 issues detected
        assert report.blocked is True  # CRITICAL issue blocks commit
        assert any(i.severity == Severity.CRITICAL for i in report.issues)
        assert any(i.severity == Severity.HIGH for i in report.issues)
        assert any(i.severity == Severity.LOW for i in report.issues)

    def test_detector_initialization(self, temp_project):
        """Test TechDebtDetector initialization."""
        # Arrange & Act
        detector = TechDebtDetector(project_root=temp_project)

        # Assert
        assert detector.project_root == temp_project

    def test_detector_with_pathlib_path(self, temp_project):
        """Test that detector accepts pathlib.Path objects."""
        # Arrange & Act
        detector = TechDebtDetector(project_root=Path(temp_project))

        # Assert
        assert isinstance(detector.project_root, (str, Path))

    def test_multiple_analyses_same_detector(self, temp_project):
        """Test running multiple analyses with same detector instance."""
        # Arrange
        (temp_project / "file1.py").write_text("def func1(): pass\n")
        detector = TechDebtDetector(project_root=temp_project)

        # Act
        report1 = detector.analyze()

        # Add more code
        (temp_project / "file2.py").write_text("def func2(): pass\n")

        report2 = detector.analyze()

        # Assert
        assert isinstance(report1, TechDebtReport)
        assert isinstance(report2, TechDebtReport)


# =============================================================================
# Test Summary
# =============================================================================

"""
Test Coverage Summary (95+ tests):

SECTION 1: Severity Enum Tests (5 tests)
- Enum values, ordering, equality, string representation

SECTION 2: TechDebtIssue Dataclass Tests (8 tests)
- Creation, required fields, severity types, equality, string representation

SECTION 3: TechDebtReport Tests (10 tests)
- Empty report, single/multiple issues, blocking logic, counts by severity

SECTION 4: Large File Detection Tests (8 tests)
- Small/medium files (no issue), large files (HIGH), huge files (CRITICAL)
- Multiple files, exact thresholds, test exclusion, recommendations

SECTION 5: Circular Import Detection Tests (8 tests)
- No circular imports, simple/complex cycles, blocking behavior
- AST parsing, relative imports, error handling

SECTION 6: RED Test Accumulation Detection Tests (7 tests)
- No RED tests, few RED tests (ok), excessive RED tests (HIGH)
- Multiple files, case sensitivity

SECTION 7: Config Proliferation Detection Tests (6 tests)
- Few configs (ok), many configs (MEDIUM), counting logic
- Exclusion of non-config classes

SECTION 8: Duplicate Directory Detection Tests (7 tests)
- Unique directories, duplicate directories (> 80% similarity)
- Threshold boundaries, similarity calculation

SECTION 9: Dead Code Detection Tests (7 tests)
- No dead code, unused imports/functions (LOW)
- Test file exclusion, recommendations

SECTION 10: Complexity Calculation Tests (10 tests)
- Simple functions (no issue), moderate/high/critical complexity
- Threshold application, radon integration

SECTION 11: TechDebtDetector.analyze() Orchestration Tests (8 tests)
- Clean project, calls all detectors, aggregates issues
- Counts by severity, blocking logic

SECTION 12: Edge Cases Tests (10 tests)
- Empty project, no Python files, permission errors
- Invalid syntax, binary files, symlinks, deep nesting, Unicode

SECTION 13: Integration Tests (5 tests)
- End-to-end workflows, detector initialization

Total: ~100 comprehensive tests covering all tech debt detection scenarios
"""
